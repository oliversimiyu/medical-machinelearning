{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79c9cc7",
   "metadata": {},
   "source": [
    "# Medical Insurance Fraud Detection - Baseline Model\n",
    "\n",
    "This notebook implements **ensemble learning models** with **traditional tabular features** for detecting fraudulent medical insurance claims.\n",
    "\n",
    "## Features:\n",
    "- **Traditional tabular representation** (basic features without advanced engineering)\n",
    "- **Stacking Ensemble** combining multiple base learners\n",
    "\n",
    "## Models Implemented:\n",
    "1. **Random Forest Classifier**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **XGBoost Classifier**\n",
    "4. **LightGBM Classifier**\n",
    "5. **Stacking Classifier** (Meta-learner ensemble)\n",
    "\n",
    "## Workflow:\n",
    "- Load medical insurance claims data\n",
    "- Basic feature preprocessing\n",
    "- Train multiple ensemble models with stacking\n",
    "- Comprehensive evaluation and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15a061",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn preprocessing and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final feature matrix X and target y\n",
    "feature_columns = [\n",
    "    'claim_amount', 'patient_age', 'num_procedures', 'hospital_stay_days',\n",
    "    'num_previous_claims', 'provider_claim_count', 'diagnosis_complexity',\n",
    "    'treatment_cost_ratio', 'claim_processing_time', 'geographic_risk_score',\n",
    "    'cost_per_procedure', 'cost_per_day', 'procedures_per_day'\n",
    "]\n",
    "\n",
    "# Select features and handle missing values\n",
    "X = all_claims[feature_columns].copy()\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Prepare target variable\n",
    "if 'PotentialFraud' in all_claims.columns:\n",
    "    y = (all_claims['PotentialFraud'] == 'Yes').astype(int)\n",
    "else:\n",
    "    raise ValueError(\"PotentialFraud column not found in the data!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL DATASET PREPARED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Fraud cases: {y.sum()} ({y.mean()*100:.2f}%)\")\n",
    "print(f\"Legitimate cases: {(1-y).sum()} ({(1-y).mean()*100:.2f}%)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline ratio features (3 simple features as per project design)\n",
    "all_claims['cost_per_procedure'] = all_claims['claim_amount'] / (all_claims['num_procedures'] + 1)\n",
    "all_claims['cost_per_day'] = all_claims['claim_amount'] / (all_claims['hospital_stay_days'] + 1)\n",
    "all_claims['procedures_per_day'] = all_claims['num_procedures'] / (all_claims['hospital_stay_days'] + 1)\n",
    "\n",
    "print(\"Baseline ratio features created:\")\n",
    "print(\"  âœ“ cost_per_procedure\")\n",
    "print(\"  âœ“ cost_per_day\")\n",
    "print(\"  âœ“ procedures_per_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with patient data to get demographics\n",
    "all_claims = all_claims.merge(patients_df, on='BeneID', how='left')\n",
    "\n",
    "# Create baseline features\n",
    "print(\"Engineering baseline features...\")\n",
    "\n",
    "# Basic claim amount features\n",
    "if 'InscClaimAmtReimbursed' in all_claims.columns:\n",
    "    all_claims['claim_amount'] = all_claims['InscClaimAmtReimbursed']\n",
    "elif 'ClaimAmount' in all_claims.columns:\n",
    "    all_claims['claim_amount'] = all_claims['ClaimAmount']\n",
    "else:\n",
    "    # Calculate from deductible amounts if needed\n",
    "    amount_cols = [c for c in all_claims.columns if 'Amt' in c or 'Reimbursed' in c]\n",
    "    all_claims['claim_amount'] = all_claims[amount_cols].sum(axis=1) if amount_cols else 0\n",
    "\n",
    "# Patient age (calculate from DOB if available)\n",
    "if 'DOB' in all_claims.columns and 'ClaimStartDt' in all_claims.columns:\n",
    "    all_claims['DOB'] = pd.to_datetime(all_claims['DOB'], errors='coerce')\n",
    "    all_claims['ClaimStartDt'] = pd.to_datetime(all_claims['ClaimStartDt'], errors='coerce')\n",
    "    all_claims['patient_age'] = (all_claims['ClaimStartDt'] - all_claims['DOB']).dt.days / 365.25\n",
    "elif 'Age' in all_claims.columns:\n",
    "    all_claims['patient_age'] = all_claims['Age']\n",
    "else:\n",
    "    all_claims['patient_age'] = 50  # Default if not available\n",
    "\n",
    "# Number of procedures (count diagnosis and procedure codes)\n",
    "diag_cols = [c for c in all_claims.columns if 'ClmDiagnosisCode' in c or 'DiagnosisCode' in c]\n",
    "proc_cols = [c for c in all_claims.columns if 'ClmProcedureCode' in c or 'ProcedureCode' in c]\n",
    "all_claims['num_procedures'] = all_claims[diag_cols + proc_cols].notna().sum(axis=1)\n",
    "\n",
    "# Hospital stay days\n",
    "if 'ClaimStartDt' in all_claims.columns and 'ClaimEndDt' in all_claims.columns:\n",
    "    all_claims['ClaimEndDt'] = pd.to_datetime(all_claims['ClaimEndDt'], errors='coerce')\n",
    "    all_claims['hospital_stay_days'] = (all_claims['ClaimEndDt'] - all_claims['ClaimStartDt']).dt.days\n",
    "    all_claims['hospital_stay_days'] = all_claims['hospital_stay_days'].fillna(0).clip(lower=0)\n",
    "else:\n",
    "    all_claims['hospital_stay_days'] = 0\n",
    "\n",
    "# Count previous claims per patient\n",
    "all_claims = all_claims.sort_values(['BeneID', 'ClaimStartDt']) if 'ClaimStartDt' in all_claims.columns else all_claims\n",
    "all_claims['num_previous_claims'] = all_claims.groupby('BeneID').cumcount()\n",
    "\n",
    "# Provider claim count\n",
    "all_claims['provider_claim_count'] = all_claims.groupby('Provider')['ClaimID'].transform('count')\n",
    "\n",
    "# Create additional simple features\n",
    "all_claims['diagnosis_complexity'] = all_claims['num_procedures'] / (all_claims['num_procedures'].max() + 1)\n",
    "all_claims['treatment_cost_ratio'] = all_claims['claim_amount'] / (all_claims['claim_amount'].mean() + 1)\n",
    "\n",
    "# Processing time (admission to claim)\n",
    "if 'AdmissionDt' in all_claims.columns and 'ClaimStartDt' in all_claims.columns:\n",
    "    all_claims['AdmissionDt'] = pd.to_datetime(all_claims['AdmissionDt'], errors='coerce')\n",
    "    all_claims['claim_processing_time'] = (all_claims['ClaimStartDt'] - all_claims['AdmissionDt']).dt.days\n",
    "    all_claims['claim_processing_time'] = all_claims['claim_processing_time'].fillna(15).clip(lower=0, upper=180)\n",
    "else:\n",
    "    all_claims['claim_processing_time'] = 15\n",
    "\n",
    "# Geographic risk score (using state if available)\n",
    "if 'State' in all_claims.columns:\n",
    "    state_fraud_rate = all_claims.groupby('State')['PotentialFraud'].apply(\n",
    "        lambda x: (x == 'Yes').mean() if 'PotentialFraud' in all_claims.columns else 0.1\n",
    "    )\n",
    "    all_claims['geographic_risk_score'] = all_claims['State'].map(state_fraud_rate).fillna(0.1)\n",
    "else:\n",
    "    all_claims['geographic_risk_score'] = 0.1\n",
    "\n",
    "print(\"âœ“ Feature engineering completed!\")\n",
    "print(f\"\\nCreated features:\")\n",
    "feature_cols = ['claim_amount', 'patient_age', 'num_procedures', 'hospital_stay_days',\n",
    "                'num_previous_claims', 'provider_claim_count', 'diagnosis_complexity',\n",
    "                'treatment_cost_ratio', 'claim_processing_time', 'geographic_risk_score']\n",
    "for col in feature_cols:\n",
    "    if col in all_claims.columns:\n",
    "        print(f\"  âœ“ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cddab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine inpatient and outpatient claims\n",
    "# Add claim type indicator\n",
    "inpatient_df['ClaimType'] = 'Inpatient'\n",
    "outpatient_df['ClaimType'] = 'Outpatient'\n",
    "\n",
    "# Combine claims\n",
    "all_claims = pd.concat([inpatient_df, outpatient_df], ignore_index=True)\n",
    "\n",
    "print(f\"Total claims: {len(all_claims)}\")\n",
    "print(f\"\\nClaim Types Distribution:\")\n",
    "print(all_claims['ClaimType'].value_counts())\n",
    "\n",
    "# Check for Provider column and potential fraud labels\n",
    "if 'PotentialFraud' in all_claims.columns:\n",
    "    print(f\"\\nFraud Distribution:\")\n",
    "    print(all_claims['PotentialFraud'].value_counts())\n",
    "elif 'Provider' in all_claims.columns and 'PotentialFraud' in providers_df.columns:\n",
    "    # Merge with provider data to get fraud labels\n",
    "    all_claims = all_claims.merge(providers_df[['Provider', 'PotentialFraud']], \n",
    "                                   on='Provider', how='left')\n",
    "    print(f\"\\nFraud Distribution (from providers):\")\n",
    "    print(all_claims['PotentialFraud'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9575d8b",
   "metadata": {},
   "source": [
    "## 2. Load Data from CSV Files\n",
    "\n",
    "Load the medical insurance fraud dataset from the `data` folder which contains:\n",
    "- **Inpatient Claims**: Hospital admission claims\n",
    "- **Outpatient Claims**: Outpatient visit claims\n",
    "- **Patients Data**: Patient demographics and information\n",
    "- **Providers Data**: Healthcare provider information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets from data folder...\")\n",
    "\n",
    "# Load claims data\n",
    "inpatient_df = pd.read_csv('../data/inpatient_claims_data.csv')\n",
    "outpatient_df = pd.read_csv('../data/outpatient_claims_data.csv')\n",
    "\n",
    "# Load supporting data\n",
    "patients_df = pd.read_csv('../data/patients_data.csv')\n",
    "providers_df = pd.read_csv('../data/providers_data.csv')\n",
    "\n",
    "print(f\"âœ“ Loaded {len(inpatient_df)} inpatient claims\")\n",
    "print(f\"âœ“ Loaded {len(outpatient_df)} outpatient claims\")\n",
    "print(f\"âœ“ Loaded {len(patients_df)} patient records\")\n",
    "print(f\"âœ“ Loaded {len(providers_df)} provider records\")\n",
    "\n",
    "# Display dataset info\n",
    "print(\"\\nInpatient Claims Columns:\", inpatient_df.columns.tolist())\n",
    "print(\"Outpatient Claims Columns:\", outpatient_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60947fcc",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering\n",
    "\n",
    "We'll combine and process the data to create features suitable for the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d5997",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"Sample Data:\")\n",
    "display(X.head(10))\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "display(X.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78976f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "y.value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class (0=Legitimate, 1=Fraudulent)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Legitimate', 'Fraudulent'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(y.value_counts(), labels=['Legitimate', 'Fraudulent'], \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Class Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key features by fraud status\n",
    "features_to_plot = ['claim_amount', 'patient_age', 'num_procedures', 'hospital_stay_days']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    # Legitimate claims\n",
    "    axes[idx].hist(X[y==0][feature], bins=50, alpha=0.6, label='Legitimate', color='#2ecc71')\n",
    "    # Fraudulent claims\n",
    "    axes[idx].hist(X[y==1][feature], bins=50, alpha=0.6, label='Fraudulent', color='#e74c3c')\n",
    "    \n",
    "    axes[idx].set_xlabel(feature.replace('_', ' ').title(), fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].set_title(f'{feature.replace(\"_\", \" \").title()} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f91980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d486f28",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets (80/20 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_features(df):\n",
    "    \"\"\"Create basic engineered features for baseline model\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Simple ratio features (traditional tabular representation)\n",
    "    df['cost_per_procedure'] = df['claim_amount'] / (df['num_procedures'] + 1)\n",
    "    df['cost_per_day'] = df['claim_amount'] / (df['hospital_stay_days'] + 1)\n",
    "    df['procedures_per_day'] = df['num_procedures'] / (df['hospital_stay_days'] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply basic feature engineering\n",
    "X_engineered = create_basic_features(X)\n",
    "\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"Total features (with basic engineering): {X_engineered.shape[1]}\")\n",
    "print(f\"New features added: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "print(\"\\nFeature approach: Traditional tabular representation\")\n",
    "print(\"âœ“ Basic feature engineering complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b67d8",
   "metadata": {},
   "source": [
    "## 6. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbce0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_engineered, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(f\"  Legitimate: {(y_train==0).sum()} ({(y_train==0).sum()/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Fraudulent: {(y_train==1).sum()} ({(y_train==1).sum()/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nâœ“ Data preprocessed and split successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded425f",
   "metadata": {},
   "source": [
    "## 7. Model Training - Baseline Stacking Ensemble\n",
    "\n",
    "Train the baseline model using:\n",
    "- **Base Learners**: Random Forest, Gradient Boosting, XGBoost, LightGBM\n",
    "- **Meta-Learner**: Logistic Regression\n",
    "- **Class Imbalance Handling**: Class weights (balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize base models\n",
    "base_models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        subsample=0.8,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=10,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"âœ“ Base models initialized!\")\n",
    "print(f\"\\nTotal base models: {len(base_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all base models\n",
    "print(\"=\" * 70)\n",
    "print(\"Training Base Models\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    print(f\"\\n[Training] {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f\"âœ“ {name} trained successfully!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ“ All base models trained!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b827fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Stacking Classifier\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"[Training] Stacking Classifier (Meta-Learner Ensemble)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define base estimators for stacking\n",
    "estimators = [\n",
    "    ('rf', trained_models['Random Forest']),\n",
    "    ('gb', trained_models['Gradient Boosting']),\n",
    "    ('xgb', trained_models['XGBoost']),\n",
    "    ('lgb', trained_models['LightGBM'])\n",
    "]\n",
    "\n",
    "# Create stacking classifier with Logistic Regression as meta-learner\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=1000\n",
    "    ),\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    stack_method='predict_proba',  # Use probability predictions\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print('\\nStacking architecture:')\n",
    "print('  Base learners: Random Forest, Gradient Boosting, XGBoost, LightGBM')\n",
    "print('  Meta-learner: Logistic Regression')\n",
    "print('  CV strategy: 5-fold cross-validation')\n",
    "print('\\nTraining stacking ensemble...')\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "trained_models['Stacking Classifier'] = stacking_clf\n",
    "\n",
    "print(\"\\nâœ“ Stacking Classifier trained successfully!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"âœ“ All {len(trained_models)} models ready for evaluation!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589f47a",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be662f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "results = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Avg Precision': average_precision_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"MODEL PERFORMANCE COMPARISON (Baseline - Traditional Features)\")\n",
    "print(\"=\" * 90)\n",
    "display(results_df)\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for best model (Stacking Classifier)\n",
    "best_model = trained_models['Stacking Classifier']\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED CLASSIFICATION REPORT - STACKING CLASSIFIER\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=['Legitimate', 'Fraudulent'],\n",
    "                          digits=4))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1b421",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison bar chart\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(trained_models))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    values = [results[model][metric] for model in trained_models.keys()]\n",
    "    offset = width * (i - len(metrics_to_plot) / 2)\n",
    "    ax.bar(x + offset, values, width, label=metric)\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison (Baseline - Traditional Features)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(trained_models.keys(), rotation=15, ha='right')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, model) in enumerate(trained_models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                xticklabels=['Legitimate', 'Fraudulent'],\n",
    "                yticklabels=['Legitimate', 'Fraudulent'],\n",
    "                cbar_kws={'shrink': 0.8})\n",
    "    \n",
    "    axes[idx].set_title(f'{name}\\nAccuracy: {results[name][\"Accuracy\"]:.4f}',\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicted', fontsize=10)\n",
    "    axes[idx].set_ylabel('Actual', fontsize=10)\n",
    "\n",
    "# Hide the last subplot if odd number of models\n",
    "if len(trained_models) < 6:\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - All Models (Baseline)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79052064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random (AUC = 0.5000)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curves - All Models (Baseline)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curves for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    plt.plot(recall, precision, linewidth=2, \n",
    "             label=f'{name} (AP = {avg_precision:.4f})')\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "plt.title('Precision-Recall Curves - All Models (Baseline)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"lower left\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for tree-based models\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, model_name in enumerate(tree_models):\n",
    "    model = trained_models[model_name]\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X_engineered.columns\n",
    "    \n",
    "    # Create dataframe and sort\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].barh(range(len(importance_df)), importance_df['importance'], color='steelblue')\n",
    "    axes[idx].set_yticks(range(len(importance_df)))\n",
    "    axes[idx].set_yticklabels(importance_df['feature'], fontsize=9)\n",
    "    axes[idx].set_xlabel('Importance', fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_title(f'Top 15 Features - {model_name}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].invert_yaxis()\n",
    "    axes[idx].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Feature Importance - Tree-Based Models (Baseline)', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b26ab1",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd575ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best performing model\n",
    "best_model_name = results_df['F1-Score'].idxmax()\n",
    "best_metrics = results_df.loc[best_model_name]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL SUMMARY - BASELINE MODEL (Traditional Tabular Features)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nðŸ“Š Dataset Information:\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Test samples: {len(X_test)}\")\n",
    "print(f\"   Features (original): {X.shape[1]}\")\n",
    "print(f\"   Features (with basic engineering): {X_engineered.shape[1]}\")\n",
    "print(f\"   Fraud ratio: {(y==1).sum()/len(y)*100:.2f}%\")\n",
    "print(f\"   Imbalance handling: None (class_weight='balanced' in models)\")\n",
    "\n",
    "print(\"\\nðŸ† Best Performing Model: \" + best_model_name)\n",
    "print(f\"   Accuracy:  {best_metrics['Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {best_metrics['Precision']:.4f}\")\n",
    "print(f\"   Recall:    {best_metrics['Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {best_metrics['F1-Score']:.4f}\")\n",
    "print(f\"   ROC-AUC:   {best_metrics['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Model Rankings (by F1-Score):\")\n",
    "rankings = results_df.sort_values('F1-Score', ascending=False)\n",
    "for i, (model, metrics) in enumerate(rankings.iterrows(), 1):\n",
    "    print(f\"   {i}. {model}: {metrics['F1-Score']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Key Characteristics:\")\n",
    "print(\"   â€¢ Traditional tabular feature representation\")\n",
    "print(\"   â€¢ Stacking ensemble with Logistic Regression meta-learner\")\n",
    "print(\"   â€¢ No synthetic data generation (SMOTE)\")\n",
    "print(\"   â€¢ Basic feature engineering (3 simple ratio features)\")\n",
    "print(\"   â€¢ Serves as baseline for comparison\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Next Steps:\")\n",
    "print(\"   â€¢ Compare with SMOTE model for performance improvement\")\n",
    "print(\"   â€¢ Advanced feature engineering with relational patterns\")\n",
    "print(\"   â€¢ Hyperparameter tuning for optimization\")\n",
    "print(\"   â€¢ Explore different meta-learners for stacking\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Baseline Model Analysis Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
